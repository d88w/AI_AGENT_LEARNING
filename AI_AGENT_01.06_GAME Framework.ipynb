{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FezaORGZ4qSznCEZRQOwUUiiSeYCDa5z","timestamp":1749593051183},{"file_id":"16TU03Dgubcuo6OPCL0mOWuLJ8cxpgL2V","timestamp":1741639424602},{"file_id":"1pLBChdZirjle6v3-iqMTIu0YJmk7ZPD6","timestamp":1741638959488},{"file_id":"1W3LEOFjAQs69PJ3rM1aYG8Cofo_de6XH","timestamp":1741638416773},{"file_id":"1Jln3bwiJnTBNAnC-iTQxkaoXOOpY1vgE","timestamp":1741638038856},{"file_id":"10USwjwaJ-1J-I_2igKIbJ-GdMDWlHKRU","timestamp":1741191570810}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!!pip install litellm\n","\n","# Important!!!\n","#\n","# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n","#\n","# <---- You will also likely want to use the \"folder\" icon to add some files\n","#       for the agent to look at\n","#\n","import os\n","from google.colab import userdata\n","api_key = userdata.get('OPENAI_API_KEY')\n","os.environ['OPENAI_API_KEY'] = api_key"],"metadata":{"id":"KEYrzG2vB8Ip","executionInfo":{"status":"ok","timestamp":1749593517315,"user_tz":420,"elapsed":19914,"user":{"displayName":"Derek Wang","userId":"16275169335761411529"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Mwe2eeOQB0cC","executionInfo":{"status":"ok","timestamp":1749593590694,"user_tz":420,"elapsed":6556,"user":{"displayName":"Derek Wang","userId":"16275169335761411529"}}},"outputs":[],"source":["import json\n","import time\n","import traceback\n","from litellm import completion\n","from dataclasses import dataclass, field\n","from typing import List, Callable, Dict, Any\n","\n","@dataclass\n","class Prompt:\n","    messages: List[Dict] = field(default_factory=list)\n","    tools: List[Dict] = field(default_factory=list)\n","    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue\n","\n","\n","def generate_response(prompt: Prompt) -> str:\n","    \"\"\"Call LLM to get response\"\"\"\n","\n","    messages = prompt.messages\n","    tools = prompt.tools\n","\n","    result = None\n","\n","    if not tools:\n","        response = completion(\n","            model=\"openai/gpt-4o\",\n","            messages=messages,\n","            max_tokens=1024\n","        )\n","        result = response.choices[0].message.content\n","    else:\n","        response = completion(\n","            model=\"openai/gpt-4o\",\n","            messages=messages,\n","            tools=tools,\n","            max_tokens=1024\n","        )\n","\n","        if response.choices[0].message.tool_calls:\n","            tool = response.choices[0].message.tool_calls[0]\n","            result = {\n","                \"tool\": tool.function.name,\n","                \"args\": json.loads(tool.function.arguments),\n","            }\n","            result = json.dumps(result)\n","        else:\n","            result = response.choices[0].message.content\n","\n","\n","    return result\n","\n","\n","@dataclass(frozen=True)\n","\n","# Goals will describe what we are trying to achieve and how to achieve it.\n","\n","class Goal:\n","    priority: int\n","    name: str\n","    description: str\n","\n","# Actions define what the agent can do. Think of them as the agent’s toolkit.\n","# Each action is a discrete capability that can be executed in the environment.\n","# The action system has two main parts: the Action class and the ActionRegistry.\n","# The actions are the interface between our agent and its environment.\n","# These are descriptions of what the agent can do to affect the environment.\n","\n","class Action:\n","    def __init__(self,\n","                 name: str,\n","                 function: Callable,\n","                 description: str,\n","                 parameters: Dict,\n","                 terminal: bool = False):\n","        self.name = name\n","        self.function = function\n","        self.description = description\n","        self.terminal = terminal\n","        self.parameters = parameters\n","\n","    def execute(self, **args) -> Any:\n","        \"\"\"Execute the action's function\"\"\"\n","        return self.function(**args)\n","\n","# When the agent provides a response, it is going to return JSON.\n","# However, we are going to want a way to lookup the actual object associated with the action indicated by the JSON.\n","# To do this, we will create an ActionRegistry that will allow us to register actions and look them up by name\n","\n","class ActionRegistry:\n","    def __init__(self):\n","        self.actions = {}\n","\n","    def register(self, action: Action):\n","        self.actions[action.name] = action\n","\n","    def get_action(self, name: str) -> [Action, None]:\n","        return self.actions.get(name, None)\n","\n","    def get_actions(self) -> List[Action]:\n","        \"\"\"Get all registered actions\"\"\"\n","        return list(self.actions.values())\n","\n","# Almost every agent needs to remember what happens from one loop iteration to the next.\n","\n","class Memory:\n","    def __init__(self):\n","        self.items = []  # Basic conversation histor\n","\n","    def add_memory(self, memory: dict):\n","        \"\"\"Add memory to working memory\"\"\"\n","        self.items.append(memory)\n","\n","    def get_memories(self, limit: int = None) -> List[Dict]:\n","        \"\"\"Get formatted conversation history for prompt\"\"\"\n","        return self.items[:limit]\n","\n","    def copy_without_system_memories(self):\n","        \"\"\"Return a copy of the memory without system memories\"\"\"\n","        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n","        memory = Memory()\n","        memory.items = filtered_items\n","        return memory\n","\n","# In our original implementation, we hardcoded our “environment” interface as a series of if/else statements and function calls.\n","# We would like to have a more modular interface that allows us to execute actions without\n","# needing to know how they are implemented or have conditional logic in the loop. This is where the Environment component comes in.\n","# It serves as a bridge between the agent and the outside world, executing actions and returning results.\n","\n","class Environment:\n","    def execute_action(self, action: Action, args: dict) -> dict:\n","        \"\"\"Execute an action and return the result.\"\"\"\n","        try:\n","            result = action.execute(**args)\n","            return self.format_result(result)\n","        except Exception as e:\n","            return {\n","                \"tool_executed\": False,\n","                \"error\": str(e),\n","                \"traceback\": traceback.format_exc()\n","            }\n","\n","    def format_result(self, result: Any) -> dict:\n","        \"\"\"Format the result with metadata.\"\"\"\n","        return {\n","            \"tool_executed\": True,\n","            \"result\": result,\n","            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n","        }\n","\n","\n","class AgentLanguage:\n","    def __init__(self):\n","        pass\n","\n","    def construct_prompt(self,\n","                         actions: List[Action],\n","                         environment: Environment,\n","                         goals: List[Goal],\n","                         memory: Memory) -> Prompt:\n","        raise NotImplementedError(\"Subclasses must implement this method\")\n","\n","\n","    def parse_response(self, response: str) -> dict:\n","        raise NotImplementedError(\"Subclasses must implement this method\")\n","\n","# The AgentLanguage component has two primary responsibilities:\n","# 1. Prompt Construction: Transforming our GAME components into a format the LLM can understand\n","# 2. Response Parsing: Interpreting the LLM’s response to determine what action the agent should take\n","class AgentFunctionCallingActionLanguage(AgentLanguage):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def format_goals(self, goals: List[Goal]) -> List:\n","        # Map all goals to a single string that concatenates their description\n","        # and combine into a single message of type system\n","        sep = \"\\n-------------------\\n\"\n","        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n","        return [\n","            {\"role\": \"system\", \"content\": goal_instructions}\n","        ]\n","\n","    def format_memory(self, memory: Memory) -> List:\n","        \"\"\"Generate response from language model\"\"\"\n","        # Map all environment results to a role:user messages\n","        # Map all assistant messages to a role:assistant messages\n","        # Map all user messages to a role:user messages\n","        items = memory.get_memories()\n","        mapped_items = []\n","        for item in items:\n","\n","            content = item.get(\"content\", None)\n","            if not content:\n","                content = json.dumps(item, indent=4)\n","\n","            if item[\"type\"] == \"assistant\":\n","                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n","            elif item[\"type\"] == \"environment\":\n","                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n","            else:\n","                mapped_items.append({\"role\": \"user\", \"content\": content})\n","\n","        return mapped_items\n","\n","    def format_actions(self, actions: List[Action]) -> [List,List]:\n","        \"\"\"Generate response from language model\"\"\"\n","\n","        tools = [\n","            {\n","                \"type\": \"function\",\n","                \"function\": {\n","                    \"name\": action.name,\n","                    # Include up to 1024 characters of the description\n","                    \"description\": action.description[:1024],\n","                    \"parameters\": action.parameters,\n","                },\n","            } for action in actions\n","        ]\n","\n","        return tools\n","\n","    #Goal #1. Prompt Construction:\n","    def construct_prompt(self,\n","                         actions: List[Action],\n","                         environment: Environment,\n","                         goals: List[Goal],\n","                         memory: Memory) -> Prompt:\n","\n","        prompt = []\n","        prompt += self.format_goals(goals)\n","        prompt += self.format_memory(memory)\n","\n","        tools = self.format_actions(actions)\n","\n","        return Prompt(messages=prompt, tools=tools)\n","\n","    def adapt_prompt_after_parsing_error(self,\n","                                         prompt: Prompt,\n","                                         response: str,\n","                                         traceback: str,\n","                                         error: Any,\n","                                         retries_left: int) -> Prompt:\n","\n","        return prompt\n","\n","    #Goal #2. Response Parsing\n","    def parse_response(self, response: str) -> dict:\n","        \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n","\n","        try:\n","            return json.loads(response)\n","\n","        except Exception as e:\n","            return {\n","                \"tool\": \"terminate\",\n","                \"args\": {\"message\":response}\n","            }\n","\n","# Now, we are going to put the components together into a reusable agent class.\n","# This class will encapsulate the GAME components and provide a simple interface for running the agent loop.\n","\n","class Agent:\n","    def __init__(self,\n","                 goals: List[Goal],\n","                 agent_language: AgentLanguage,\n","                 action_registry: ActionRegistry,\n","                 generate_response: Callable[[Prompt], str],\n","                 environment: Environment):\n","        \"\"\"\n","        Initialize an agent with its core GAME components\n","        \"\"\"\n","        self.goals = goals\n","        self.generate_response = generate_response\n","        self.agent_language = agent_language\n","        self.actions = action_registry\n","        self.environment = environment\n","\n","    # When the agent loop begins, it first constructs a prompt using the construct_prompt method\n","    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n","        \"\"\"Build prompt with memory context\"\"\"\n","        return self.agent_language.construct_prompt(\n","            actions=actions.get_actions(),\n","            environment=self.environment,\n","            goals=goals,\n","            memory=memory\n","        )\n","\n","    # Once the language model returns a response, the agent parses it to identify the intended action.\n","    # The parsing will generally be just getting the tool calls from the response, however the agent language gets to decide how this is done.\n","    # Once the response is parsed, the agent can look up the action in the ActionRegistry\n","    def get_action(self, response):\n","        invocation = self.agent_language.parse_response(response)\n","        action = self.actions.get_action(invocation[\"tool\"])\n","        return action, invocation\n","\n","    # The agent checks if it should terminate the loop\n","    # This allows certain actions (like a “terminate” action) to signal that the agent has finished its work.\n","    def should_terminate(self, response: str) -> bool:\n","        action_def, _ = self.get_action(response)\n","        return action_def.terminal\n","\n","    def set_current_task(self, memory: Memory, task: str):\n","        memory.add_memory({\"type\": \"user\", \"content\": task})\n","\n","    # After execution, the agent updates its memory with both its decision and the result:\n","    def update_memory(self, memory: Memory, response: str, result: dict):\n","        \"\"\"\n","        Update memory with the agent's decision and the environment's response.\n","        \"\"\"\n","        new_memories = [\n","            {\"type\": \"assistant\", \"content\": response},\n","            {\"type\": \"environment\", \"content\": json.dumps(result)}\n","        ]\n","        for m in new_memories:\n","            memory.add_memory(m)\n","\n","    # Next, the agent sends this prompt to the language model\n","    # The generate_response function is a simple python function provided during initialization.\n","    # This abstraction allows the framework to work with different language models without changing the core loop.\n","    # We will use LiteLLM to call the LLM, but you could easily swap this out for any other LLM provider.\n","    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n","        response = self.generate_response(full_prompt)\n","        return response\n","\n","    # This follows the flow in the next cell below\n","    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n","        \"\"\"\n","        Execute the GAME loop for this agent with a maximum iteration limit.\n","        \"\"\"\n","        memory = memory or Memory()\n","        self.set_current_task(memory, user_input)\n","\n","        for _ in range(max_iterations):\n","            # Construct a prompt that includes the Goals, Actions, and the current Memory\n","            prompt = self.construct_prompt(self.goals, memory, self.actions)\n","\n","            print(\"Agent thinking...\")\n","            # Generate a response from the agent\n","            response = self.prompt_llm_for_action(prompt)\n","            print(f\"Agent Decision: {response}\")\n","\n","            # Determine which action the agent wants to execute\n","            action, invocation = self.get_action(response)\n","\n","            # Execute the action in the environment\n","            result = self.environment.execute_action(action, invocation[\"args\"])\n","            print(f\"Action Result: {result}\")\n","\n","            # Update the agent's memory with information about what happened\n","            self.update_memory(memory, response, result)\n","\n","            # Check if the agent has decided to terminate\n","            if self.should_terminate(response):\n","                break\n","\n","        return memory\n"]},{"cell_type":"markdown","source":["# The Flow of Information Through the Loop\n","To better understand how these components interact, let’s trace how information flows through a single iteration of the loop:\n","\n","1. The `Memory` provides context about what the user has asked the agent to do and past decisions and results from the agent loop\n","2. The `Goals` define what the agent is trying to accomplish and rules on how to accomplish it\n","3. The `ActionRegistry` defines what the agent can do and helps lookup the action to execute by name\n","4. The `AgentLanguage` formats Memory, Actions, and Goals into a prompt for the LLM\n","5. The LLM generates a response choosing an action\n","6. The `AgentLanguage` parses the response into an action invocation, which will typically be extracted from tool calls\n","7. The `Environment` executes the action with the given arguments\n","8. The result is stored back in `Memory`\n","9. The loop repeats with the updated memory until the agent calls a terminal tool or reaches the maximum number of iterations"],"metadata":{"id":"HofVTzbH-VsQ"}},{"cell_type":"code","source":["    # Define the agent's goals\n","    # We broadly use the term “goal” to encompass both “what” the agent is trying to achieve and “how” it should approach the task.\n","    goals = [\n","        Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n","        Goal(priority=1, name=\"Terminate\", description=\"Call the terminate call when you have read all the files \"\n","                                                       \"and provide the content of the README in the terminate message\")\n","    ]\n","\n","    # Define the agent's language\n","    agent_language = AgentFunctionCallingActionLanguage()\n","\n","    def read_project_file(name: str) -> str:\n","        with open(name, \"r\") as f:\n","            return f.read()\n","\n","    def list_project_files() -> List[str]:\n","        return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n","\n","\n","    # Define the action registry and register some actions\n","    # We convert our tool functions into properly structured Actions in our AgentRegistry\n","    action_registry = ActionRegistry()\n","    action_registry.register(Action(\n","        name=\"list_project_files\",\n","        function=list_project_files,\n","        description=\"Lists all files in the project.\",\n","        parameters={},\n","        terminal=False\n","    ))\n","    action_registry.register(Action(\n","        name=\"read_project_file\",\n","        function=read_project_file,\n","        description=\"Reads a file from the project.\",\n","        parameters={\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"name\": {\"type\": \"string\"}\n","            },\n","            \"required\": [\"name\"]\n","        },\n","        terminal=False\n","    ))\n","    action_registry.register(Action(\n","        name=\"terminate\",\n","        function=lambda message: f\"{message}\\nTerminating...\",\n","        description=\"Terminates the session and prints the message to the user.\",\n","        parameters={\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"message\": {\"type\": \"string\"}\n","            },\n","            \"required\": []\n","        },\n","        terminal=True\n","    ))\n","\n","    # Define the environment\n","    environment = Environment()\n","\n","    # Create an agent instance\n","    agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n","\n","    # Run the agent with user input\n","    user_input = \"Write a README for this project.\"\n","    final_memory = agent.run(user_input)\n","\n","    # Print the final memory\n","    print(final_memory.get_memories())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PC3ncxezoJC","executionInfo":{"status":"ok","timestamp":1749593599143,"user_tz":420,"elapsed":5111,"user":{"displayName":"Derek Wang","userId":"16275169335761411529"}},"outputId":"8aeb6555-584f-4b48-ebd9-163466693d82"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Agent thinking...\n","Agent Decision: {\"tool\": \"list_project_files\", \"args\": {}}\n","Action Result: {'tool_executed': True, 'result': [], 'timestamp': '2025-06-10T22:13:16+0000'}\n","Agent thinking...\n","Agent Decision: {\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project to read. Consequently, I'm unable to provide you with details typically found in a README file. If you have specific content or guidelines you'd like included, please let me know!\"}}\n","Action Result: {'tool_executed': True, 'result': \"It seems there are no files in the project to read. Consequently, I'm unable to provide you with details typically found in a README file. If you have specific content or guidelines you'd like included, please let me know!\\nTerminating...\", 'timestamp': '2025-06-10T22:13:19+0000'}\n","[{'type': 'user', 'content': 'Write a README for this project.'}, {'type': 'assistant', 'content': '{\"tool\": \"list_project_files\", \"args\": {}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": [], \"timestamp\": \"2025-06-10T22:13:16+0000\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project to read. Consequently, I\\'m unable to provide you with details typically found in a README file. If you have specific content or guidelines you\\'d like included, please let me know!\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"It seems there are no files in the project to read. Consequently, I\\'m unable to provide you with details typically found in a README file. If you have specific content or guidelines you\\'d like included, please let me know!\\\\nTerminating...\", \"timestamp\": \"2025-06-10T22:13:19+0000\"}'}]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"w0KJxE-555gZ"},"execution_count":null,"outputs":[]}]}