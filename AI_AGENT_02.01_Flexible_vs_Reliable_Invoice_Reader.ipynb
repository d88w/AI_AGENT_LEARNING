{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkXsrAbJuJSstGjJCWegek"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Imagine we’re building an agent to automate accounts payable processing. Every day, the agent receives dozens of emails with attached invoices from different vendors, each using their own unique format and layout. Some are PDFs, others are scanned images that have been converted to text, and a few even arrive as plain text in the email body. Our agent needs to understand each invoice, extract key information like the invoice number, date, amount, and line items, and then insert this data into the company’s accounting database. Without automation, this would be a tedious manual task requiring someone to read each invoice and transcribe the important details.\n","\n","This is where the computational power of large language models becomes transformative. Through self-prompting, our agent can use an LLM as a universal parser that understands the natural structure of invoices, regardless of their format. The LLM can read an invoice like a human would, identifying key information based on context and common patterns, then output that information in a structured format our agent can process. We don’t need to write separate parsers for each vendor’s invoice format or maintain complex rules about where to find specific information - the LLM can handle all of that complexity for us.\n","\n","Here’s how we can implement this capability as a reusable tool for our agent:"],"metadata":{"id":"tVHdtda9GQRX"}},{"cell_type":"code","source":["@register_tool()\n","def prompt_llm_for_json(action_context: ActionContext, schema: dict, prompt: str):\n","    \"\"\"\n","    Have the LLM generate JSON in response to a prompt. Always use this tool when you need structured data out of the LLM.\n","    This function takes a JSON schema that specifies the structure of the expected JSON response.\n","\n","    Args:\n","        schema: JSON schema defining the expected structure\n","        prompt: The prompt to send to the LLM\n","\n","    Returns:\n","        A dictionary matching the provided schema with extracted information\n","    \"\"\"\n","    generate_response = action_context.get(\"llm\")\n","\n","    # Try up to 3 times to get valid JSON\n","    for i in range(3):\n","        try:\n","            # Send prompt with schema instruction and get response\n","            response = generate_response(Prompt(messages=[\n","                {\"role\": \"system\",\n","                 \"content\": f\"You MUST produce output that adheres to the following JSON schema:\\n\\n{json.dumps(schema, indent=4)}. Output your JSON in a ```json markdown block.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ]))\n","\n","            # Check if the response has json inside of a markdown code block\n","            if \"```json\" in response:\n","                # Search from the front and then the back\n","                start = response.find(\"```json\")\n","                end = response.rfind(\"```\")\n","                response = response[start+7:end].strip()\n","\n","            # Parse and validate the JSON response\n","            return json.loads(response)\n","\n","        except Exception as e:\n","            if i == 2:  # On last try, raise the error\n","                raise e\n","            print(f\"Error generating response: {e}\")\n","            print(\"Retrying...\")"],"metadata":{"id":"a72ow-cbGYg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You may have noticed a new action_context parameter above. Don’t worry about that for now, we will talk about this architectural choice in a later section. For now, just know that it is a context object that contains the LLM and other useful information.\n","\n","With this tool in place, we can extract structured data from any text input. For example, an agent processing business documents could extract information in standardized formats:\n","\n","From an invoice:"],"metadata":{"id":"Fbbid94LGqlM"}},{"cell_type":"code","source":["invoice_schema = {\n","    \"type\": \"object\",\n","    \"properties\": {\n","        \"invoice_number\": {\"type\": \"string\"},\n","        \"date\": {\"type\": \"string\"},\n","        \"amount\": {\"type\": \"number\"},\n","        \"line_items\": {\n","            \"type\": \"array\",\n","            \"items\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"description\": {\"type\": \"string\"},\n","                    \"quantity\": {\"type\": \"number\"},\n","                    \"unit_price\": {\"type\": \"number\"}\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","extracted_data = prompt_llm_for_json(\n","    action_context=context,\n","    schema=invoice_schema,\n","    prompt=\"Extract invoice details from this text: 'INVOICE #1234...'\"\n",")"],"metadata":{"id":"8riYdjz5GlOm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The tool works by combining several key elements:\n","\n","- A system message that firmly instructs the LLM to adhere to the provided JSON schema\n","- Retry logic to handle potential parsing failures\n","- Support for both direct JSON output and markdown-formatted JSON\n","- Error handling to ensure we either get valid JSON or fail explicitly\n","\n","What makes this approach especially valuable is that it creates a reliable bridge between unstructured text and structured data processing. The agent can use this tool whenever it needs to convert natural language information into a format that other systems can process programmatically. This enables workflows where the agent can:\n","\n","Receive unstructured text input from various sources\n","Use prompt_llm_for_json to extract relevant information in a structured format\n","Pass the structured data to other APIs or services for further processing\n","Make decisions based on the processed results"],"metadata":{"id":"B6RWvkfQG5xn"}},{"cell_type":"markdown","source":["# Balancing Flexibility and Reliability in Data Extraction\n","\n","Below is an example to make it more reliable BUT less flexible\n","\n","Here we specify it is for invoice and tell it more information what each element of an invoice would look like.\n"],"metadata":{"id":"2sqmjTDoHr7h"}},{"cell_type":"code","source":["@register_tool(tags=[\"document_processing\", \"invoices\"])\n","def extract_invoice_data(action_context: ActionContext, document_text: str) -> dict:\n","    \"\"\"\n","    Extract standardized invoice data from document text. This tool enforces a consistent\n","    schema for invoice data extraction across all documents.\n","\n","    Args:\n","        document_text: The text content of the invoice to process\n","\n","    Returns:\n","        A dictionary containing extracted invoice data in a standardized format\n","    \"\"\"\n","    # Define a fixed schema for invoice data\n","    invoice_schema = {\n","        \"type\": \"object\",\n","        \"required\": [\"invoice_number\", \"date\", \"amount\"],  # These fields must be present\n","        \"properties\": {\n","            \"invoice_number\": {\"type\": \"string\"},\n","            \"date\": {\"type\": \"string\", \"format\": \"date\"},\n","            \"amount\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"value\": {\"type\": \"number\"},\n","                    \"currency\": {\"type\": \"string\"}\n","                },\n","                \"required\": [\"value\", \"currency\"]\n","            },\n","            \"vendor\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"name\": {\"type\": \"string\"},\n","                    \"tax_id\": {\"type\": \"string\"},\n","                    \"address\": {\"type\": \"string\"}\n","                },\n","                \"required\": [\"name\"]\n","            },\n","            \"line_items\": {\n","                \"type\": \"array\",\n","                \"items\": {\n","                    \"type\": \"object\",\n","                    \"properties\": {\n","                        \"description\": {\"type\": \"string\"},\n","                        \"quantity\": {\"type\": \"number\"},\n","                        \"unit_price\": {\"type\": \"number\"},\n","                        \"total\": {\"type\": \"number\"}\n","                    },\n","                    \"required\": [\"description\", \"total\"]\n","                }\n","            }\n","        }\n","    }\n","\n","    # Create a focused prompt that guides the LLM in invoice extraction\n","    extraction_prompt = f\"\"\"\n","    Extract invoice information from the following document text.\n","    Focus on identifying:\n","    - Invoice number (usually labeled as 'Invoice #', 'Reference', etc.)\n","    - Date (any dates labeled as 'Invoice Date', 'Issue Date', etc.)\n","    - Amount (total amount due, including currency)\n","    - Vendor information (company name, tax ID if present, address)\n","    - Line items (individual charges and their details)\n","\n","    Document text:\n","    {document_text}\n","    \"\"\"\n","\n","    # Use our general extraction tool with the specialized schema and prompt\n","    return prompt_llm_for_json(\n","        action_context=action_context,\n","        schema=invoice_schema,\n","        prompt=extraction_prompt\n","    )"],"metadata":{"id":"IOhyWIrHHUG6","executionInfo":{"status":"ok","timestamp":1749748220736,"user_tz":420,"elapsed":41,"user":{"displayName":"Derek Wang","userId":"16275169335761411529"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This specialized approach offers several advantages:\n","\n","- Data Consistency: The fixed schema ensures that invoice data is always structured the same way, making it easier to work with downstream systems like databases or accounting software.\n","\n","- Required Fields: We can specify which fields are required, ensuring critical information is always extracted or an error is raised if it can’t be found.\n","\n","- Field Validation: The schema can include format specifications (like ensuring dates are properly formatted) and field-specific constraints.\n","\n","- Focused Prompting: We can provide detailed guidance to the LLM about where to look for specific information, improving extraction accuracy.\n","\n","However, this specialization also means we need to create and maintain separate extraction tools for each type of document we want to process. If we later need to handle purchase orders, receipts, or contracts, we’ll need to implement new tools for each."],"metadata":{"id":"r-HTuT9bIXIM"}},{"cell_type":"markdown","source":["\n","\n","# The choice between these approaches often depends on your specific needs:\n","\n","**Use specialized tools when:**\n","- Data consistency is critical\n","- You have a well-defined set of document types\n","- You need to enforce specific validation rules\n","- The extracted data feeds into other systems with strict requirements\n","\n","**Use the general-purpose approach when:**\n","\n","- You need to handle a wide variety of document types\n","- Document formats and requirements change frequently\n","- You’re prototyping or exploring new use cases\n","- The downstream systems are flexible about data format"],"metadata":{"id":"0d-A7-lKIyUO"}}]}